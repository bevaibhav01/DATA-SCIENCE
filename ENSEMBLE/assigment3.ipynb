{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326fdc33-585f-4cfd-935e-1b491ff54072",
   "metadata": {},
   "source": [
    "Q1. What is an ensemble technique in machine learning?\n",
    "\n",
    "\n",
    "Ensemble methods are techniques that create multiple models and then combine them to produce improved results. Ensemble methods in machine learning usually produce more accurate solutions than a single model would. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee536a4-1900-4288-93cb-d7289eaa8e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7085e047-eb84-4b4c-9d33-e392af18fbed",
   "metadata": {},
   "source": [
    "Q2. Why are ensemble techniques used in machine learning?\n",
    "\n",
    "\n",
    "Ensemble techniques are used in machine learning for several reasons:\n",
    "\n",
    "Improved Predictive Performance: Ensemble methods combine the predictions of multiple individual models to produce a stronger overall prediction. This often results in higher accuracy and better generalization to new data compared to using a single model.\n",
    "Reduction of Overfitting: By aggregating the predictions of multiple models, ensemble methods can reduce the risk of overfitting, especially when individual models have different biases or are trained on different subsets of data. This helps in producing more robust models that perform well on unseen data.\n",
    "Handling Complex Relationships: Ensembles can capture complex relationships in the data that may be missed by individual models. By combining the strengths of different models, ensembles can effectively handle various types of data and relationships within it.\n",
    "Robustness to Noise: Ensemble methods can be more robust to noisy data or outliers since they average out individual errors or biases. This can lead to more stable predictions even in the presence of noisy or imperfect data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2289e868-559c-4353-b91a-8b50ec7d23b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "054db95e-2c24-4e2d-afc0-e72ec279208e",
   "metadata": {},
   "source": [
    "Q3. What is bagging?\n",
    "\n",
    "Bagging, short for Bootstrap Aggregating, is an ensemble technique in machine learning used to improve the stability and accuracy of models, particularly decision trees and other high-variance models.\n",
    "\n",
    "Here's how bagging works:\n",
    "\n",
    "Bootstrap Sampling: Bagging involves creating multiple subsets of the original training data through bootstrap sampling. Bootstrap sampling randomly selects samples from the original dataset with replacement, meaning that each sample can be selected multiple times or not at all for each subset. This process generates several diverse subsets, each containing a portion of the original data.\n",
    "Model Training: After creating the subsets, a base model (such as a decision tree) is trained on each of them independently. Since each subset is slightly different due to the random sampling, each model captures different patterns and errors in the data.\n",
    "Aggregation: Once all the models are trained, predictions are made by aggregating the predictions of all base models. For regression problems, the predictions are usually averaged, while for classification problems, voting or averaging of class probabilities is often used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd5d4d4-4566-4569-bd92-bc331b6f3a16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83696dcc-34b5-4be7-8be6-5e7c8e758947",
   "metadata": {},
   "source": [
    "Q4. What is boosting?\n",
    "\n",
    "boosting is techniqe where models are trained sequantially and results are combined weak models are being made then combing them create strong learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4acb04-8aa7-4555-ad59-f827d004f35c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd1ba440-8755-4356-9553-24ab24326451",
   "metadata": {},
   "source": [
    "Q5. What are the benefits of using ensemble techniques?\n",
    "\n",
    "genralized models are created\n",
    "reduced overfitting\n",
    "robust to noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb09118-15b8-43f0-9b58-74abc80f5450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d8a1da-e46d-4a90-9a40-3d9264e166ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80260c78-6a48-4386-96cb-f51548d90343",
   "metadata": {},
   "source": [
    "Q6. Are ensemble techniques always better than individual models?\n",
    "\n",
    "yes ensemble techniques are always better in terms of test accuracy and ovefitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5d5ea1-e1f5-420a-b9a5-dff7be06a4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7c12c79-ba27-4b10-8e82-b92da9be4e25",
   "metadata": {},
   "source": [
    "Q7. How is the confidence interval calculated using bootstrap?\n",
    "\n",
    "The confidence interval (CI) calculated using bootstrap resampling involves estimating the uncertainty or variability of a statistic (such as the mean, median, or any other parameter) by repeatedly resampling with replacement from the original data and then calculating the statistic of interest from each resampled dataset. Here's a general outline of how the confidence interval is calculated using the bootstrap method:\n",
    "\n",
    "Bootstrap Sampling: Randomly select a large number of bootstrap samples (with replacement) from the original dataset. Each bootstrap sample should have the same size as the original dataset.\n",
    "Compute Statistic: For each bootstrap sample, compute the statistic of interest (e.g., mean, median, standard deviation) from the resampled data. This creates a distribution of the statistic.\n",
    "Calculate Confidence Interval: From the distribution of the statistic obtained from the bootstrap samples, determine the lower and upper bounds of the confidence interval. Commonly used percentiles, such as the 2.5th and 97.5th percentiles, are often used to define a 95% confidence interval. These percentiles provide the range within which the true parameter value is likely to lie with 95% confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eef142-52d1-4aa4-b148-cf7ed4b1811f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1a78c76-71d1-4728-9b26-e2bd44912067",
   "metadata": {},
   "source": [
    "Q8. How does bootstrap work and What are the steps involved in bootstrap?\n",
    "\n",
    "\n",
    "Bootstrap is a resampling technique used to estimate the variability of a statistic or to assess the accuracy of a sample estimate by generating multiple samples (bootstrap samples) from the original data. The main idea behind bootstrap is to mimic the process of sampling from the population by sampling with replacement from the observed data.\n",
    "\n",
    "Here are the steps involved in the bootstrap procedure:\n",
    "\n",
    "Original Data: Begin with a dataset containing observed data, typically represented as a vector or matrix.\n",
    "Resampling with Replacement: Generate multiple bootstrap samples by randomly selecting observations from the original dataset with replacement. Each bootstrap sample is of the same size as the original dataset, but individual observations may appear more than once or not at all in each sample.\n",
    "Statistic Calculation: Compute the statistic of interest for each bootstrap sample. This statistic could be a mean, median, standard deviation, correlation, or any other parameter that characterizes the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc9858-2d6a-4a02-8b6e-740d890ccb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "266acb87-97aa-447c-8817-4ddd4df851cb",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to estimate the mean height of a population of trees. They measure the height of a\n",
    "sample of 50 trees and obtain a mean height of 15 meters and a standard deviation of 2 meters. Use\n",
    "bootstrap to estimate the 95% confidence interval for the population mean height.\n",
    "\n",
    "\n",
    "\n",
    "To estimate the 95% confidence interval for the population mean height of the trees using bootstrap, we'll follow these steps:\n",
    "\n",
    "Generate Bootstrap Samples: Resample with replacement from the original sample of tree heights.\n",
    "Calculate the Mean: Calculate the mean height for each bootstrap sample.\n",
    "Repeat: Repeat steps 1 and 2 a large number of times.\n",
    "Compute Confidence Interval: Calculate the 2.5th and 97.5th percentiles of the distribution of bootstrap means to obtain the confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28414241-1e72-483d-9c44-b1e4cdee7d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
